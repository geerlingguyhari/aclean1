---

Interactive Demo Script

Why HPA?

"Alright team, let's talk about a common nightmare: your app suddenly gets popular and... crashes.
 If traffic to your app suddenly tripled right now, what would happen?"
 
(--> "It would slow down!", "We'd get errors!", "We'd panic and manually scale!")


"Exactly! Painful stuff. This is why we have the Horizontal Pod Autoscaler (HPA), our automated operations team.


Behind the Scenes: Theory Notes

· How it Works: The HPA controller checks metrics every 15-30 seconds. 
  It calculates the desired replica count using the formula above and updates the Deployment.


· Multi-Metric Logic: HPA calculates a replica count for each metric (CPU, Memory) and chooses the highest number. 
                       This ensures all resource constraints are met.
· API Versions: Use autoscaling/v2 (as in our YAML). The older v1 only supports CPU.
· Beyond CPU/Memory: HPA can scale on custom metrics (e.g., requests per second, queue length) using the Prometheus Adapter, 
                     making it incredibly powerful.




 Let's see it in action. First, let's check our initial state."

```bash
kubectl get deployment php-apache
kubectl get hpa php-apache-hpa
```

Output:

```
NAME READY UP-TO-DATE AVAILABLE AGE
php-apache 1/1 1 1 5m

NAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE
php-apache-hpa Deployment 0%/50%, 0%/80% 1 10 1 5m
```

"Perfect. 1 pod, minding its own business, with 0% CPU and memory usage. 
Now, I'm going to simulate a traffic spike. Quick prediction: What will happen to the number of pods?"

(-----> "It will go up!", "Maybe to 3 or 4?")

---

"How HPA scales"

"Let's find out! I'll run a command to generate massive load. Everyone, watch the TARGETS and REPLICAS columns in the second terminal."

```bash
# Terminal 1: Watch the HPA live
kubectl get hpa php-apache-hpa -w

# Terminal 2: Generate the load (the storm!)
kubectl run -i --tty load-generator --rm --image=busybox:1.28 --restart=Never -- /bin/sh -c "while sleep 0.01; do wget -q -O- http://php-apache; done"
```

"Look at that CPU soar! It's at 250% of our target! The HPA is now calculating what to do. 
We use this formula to calculate How many replicas should it create?"

The Calculation

· Formula: desiredReplicas = ceil[currentReplicas × (currentMetricValue / desiredMetricValue)]
· Math: ceil[1 * (250 / 50)] = ceil[5] = 5
· Answer: "It needs 5 replicas to handle this load!"

Now Watch the REPLICAS count—it's jumping from 1 to 4, and now to 5! Our app is scaling out automatically to handle the load.
 No downtime, no panic. 
 

The Metrics Server crucial component allows HPA to even see this CPU usage
Without the Metrics Server, HPA is blind. And it needs those resource:requests we defined to do the math."

## 6. Calculating Replicas for CPU and Memory

### CPU-Based Calculation:
- **Target**: 50% CPU utilization.
- **Current**: 250% CPU utilization across all pods.
- **Current Replicas**: 2.
- **Desired Replicas** = ceil[2 × (250 / 50)] = ceil[2 × 5] = **10 replicas** [citation:2].

### Memory-Based Calculation:
- **Target**: 80% memory utilization.
- **Current**: 160% memory utilization.
- **Current Replicas**: 3.
- **Desired Replicas** = ceil[3 × (160 / 80)] = ceil[3 × 2] = **6 replicas**.

---



"Now, let's stop the load." (Press Ctrl+C in the load-generator terminal).

"The traffic is gone. What happens next? And how quickly?"

"It will scale down, but not instantly. Why? Because Kubernetes is smart and avoids thrashing. 
It uses a stabilization window (we set it to 5 minutes) to ensure the traffic is really gone before scaling down. 
Let's watch it gracefully return to 1 replica, saving us money now that the demand is over."

---

 "So, let's recap. What are the three key things we defined in our HPA YAML to make this work?"

1. scaleTargetRef: So it knows what to scale (our php-apache deployment).
2. min/max replicas: So it knows the bounds (1 to 10). Safety first!
3. metrics: So it knows when to scale (CPU > 50% OR Memory > 80%).

When & Why to Use HPA:

· When: Any stateless workload with variable traffic (web apps, APIs, microservices, batch jobs).
· Why: To maintain performance during spikes and reduce costs during no load.

Best Practices:

· Always define resource requests (HPA breaks without them).
· Set sensible maxReplicas to prevent runaway scaling from a configuration bug.
· Use behavior to control scaling speed for stateful or sensitive applications.


Presenter: "And that's it! From panic-driven operations to automated, resilient scaling. Any questions?"

---



This comprehensive guide provides everything you need to execute a flawless and engaging demo while having the deep theory on hand to answer any question.

